# Project Execution Results

## Homework 1 ‚Äî ETL Pipeline Results

### 1.1 Extract
- **Data Source**: DummyJSON API
- **Records Retrieved**:
  - Products: 194
  - Users: 208
  - Carts/Orders: 20

### 1.2 Transform (3NF Normalization)
**Normalized Tables**:

| Table          | Records | Description |
|----------------|--------:|-------------|
| addresses      |     416 | Physical addresses |
| banks          |     208 | Bank card info |
| companies      |     208 | Company data |
| categories     |      24 | Product categories |
| users          |     208 | User profiles |
| products       |     194 | Product catalog |
| product_tags   |     364 | Product tags |
| product_images |     474 | Product images |
| reviews        |     582 | Product reviews |
| orders         |      50 | Customer orders |
| order_items    |     198 | Order line items |


### 1.3 Load ‚Üí PostgreSQL (3NF)

**Insert Performance Comparison**:

| Method | Records | Time (s) | Records/sec |
|--------|---------|----------|-------------|
| Single INSERT | 1,000 | 0.127    | 7,874       |
| Batch INSERT (1000) | 10,000 | 0.128    | 78,125      |

**Conclusion**: Batch insert is **9.9x faster** than single insert.

### 1.4 Load ‚Üí MongoDB (Denormalized)

**Denormalized Collections**:

| Collection | Documents | Size    | Time (s) |
|------------|-----------|---------|----------|
| users | 208 | 0.29 MB | 0.011s |
| products | 194 | 0.32 MB | 0.007s|
| orders | 20 | 0.07 MB | 0.007s|


### 1.5 Redis Cache Performance

**Cache Statistics**:

| Metric | Value   |
|--------|---------|
| Users cached | 208     |
| Products cached | 194     |
| Orders cached | 50      |
| Memory used | 1.78 MB |

### 1.6 **Performance Comparison Table**

| Operation | PostgreSQL | MongoDB | Redis | Winner |
|-----------|------------|---------|-------|--------|
| **Insert 10k records** | 0.127s     | 0.088s | 0.081s | üèÜ Redis |
| **Read single item (avg)** | 0.14ms     | 0.18ms | 0.10ms | üèÜ Redis |
| **Read filtered set (avg)** | 0.29ms     | 0.43ms | N/A | üèÜ PostgreSQL |

**Conclusions**:
- Redis is fastest for single-item reads (caching)
- MongoDB is fastest for bulk inserts
- PostgreSQL is best for complex filtered queries

---

## Homework 2 ‚Äî File Formats Results

### Format Comparison

| Format | Size (MB) | Rows | Columns | Read time (s) | Write time (s) |
|--------|-----------|------|---------|---------------|----------------|
| CSV | 4.41 | 10,000 | 31 | 0.231 | 0.078 |
| JSON | 9.99 | 10,000 | 31 | 0.029 | 0.125 |
| Avro | 4.26 | 10,000 | 31 | 0.074 | 0.068 |
| Parquet | 0.48 | 10,000 | 31 | 0.113 | 0.260 |

### Best Performers

| Metric | Winner | Value |
|--------|--------|-------|
| üèÜ **Smallest file** | Parquet | 0.48 MB (compression 10.4:1) |
| üèÜ **Fastest read** | JSON | 0.029s |
| üèÜ **Fastest write** | Avro | 0.068s |

**Conclusions**:
- **Parquet** ‚Äî best compression for analytical workloads
- **JSON** ‚Äî fastest read due to native Python support
- **Avro** ‚Äî balanced option for streaming
- **CSV** ‚Äî worst compression, slow read

---

## Homework 3 ‚Äî Schema Comparison Results

### 3.1 Schema Sizes

| Schema | Tables/Collections | Complexity |
|--------|-------------------|-------------|
| 3NF | 11 tables | High (many JOINs) |
| Star | 5 tables | Medium |
| Snowflake | 9 tables | High (normalized dims) |

### 3.2 Query Performance Benchmark

**Test Queries** (average of 5 iterations):

| Query | 3NF Time | Star Time | Snowflake Time | Winner |
|-------|----------|-----------|----------------|--------|
| Revenue by Product | 0.0038s | 0.0010s | 0.0017s | üèÜ Star |
| Top Users | 0.0006s | 0.0005s | 0.0005s | üèÜ Star/Snow (tie) |
| Monthly Revenue | 0.0003s | 0.0005s | 0.0004s | üèÜ 3NF |
| Complex JOIN | 0.0015s | 0.0015s | 0.0018s | üèÜ 3NF/Star (tie) |
| Heavy Aggregations | 0.0005s | 0.0003s | 0.0003s | üèÜ Star/Snow |

**Average Query Time**:

| Schema | Avg Time | Performance |
|--------|----------|-------------|
| 3NF | 0.0013s | Baseline |
| Star | 0.0008s | **38% faster** üèÜ |
| Snowflake | 0.0009s | **31% faster** |

**Conclusions**:
- **Star Schema** is fastest for OLAP queries
- **3NF** is better for transactional queries (OLTP)
- **Snowflake** balances normalization and speed
- Star schema wins due to denormalized dimensions (fewer JOINs)

---

## Bonus Features Implemented

### ‚úÖ 1. JOIN Performance Comparison
- Detailed benchmark in `results/schema_benchmark.txt`
- Star schema **38% faster** than 3NF for analytical queries

### ‚úÖ 2. Auto-generate dim_date
- Date generation 2020-2026 (2191 records)
- Attributes: year, quarter, month, week, fiscal_year, is_weekend, is_holiday
- Implementation in `load/load_star_schema.py:_generate_date_dimension()`

### ‚úÖ 3. Export Fact Table
- Export to Parquet (compressed): 0.XX MB
- Export to JSON: X.XX MB
- Code: `export/export_fact_tables.py`

### ‚úÖ 4. Docker Compose
- PostgreSQL (port 5432)
- MongoDB (port 27017)
- Redis (port 6379)
- pgAdmin (port 5050)
- Redis Commander (port 8081)

---

## Key Conclusions

### When to use which storage system:

1. **PostgreSQL (3NF)**:
   - ‚úÖ Transactional workloads (OLTP)
   - ‚úÖ Strong consistency, ACID
   - ‚úÖ Complex queries with many JOINs
   - ‚ùå Slower for analytical queries

2. **PostgreSQL (Star/Snowflake)**:
   - ‚úÖ Analytical workloads (OLAP)
   - ‚úÖ Fast aggregations
   - ‚úÖ Data warehousing
   - ‚ùå Redundancy in Star schema

3. **MongoDB**:
   - ‚úÖ Flexible schema
   - ‚úÖ Fast bulk insert
   - ‚úÖ Nested/hierarchical data
   - ‚ùå No JOINs, limited aggregations

4. **Redis**:
   - ‚úÖ Ultra-fast reads (sub-millisecond)
   - ‚úÖ Session cache, hot data
   - ‚úÖ Real-time applications
   - ‚ùå In-memory (expensive), no persistence by default

### File Format Recommendations:

- **CSV**: Human-readable, universally supported, but poor compression
- **JSON**: Flexible, easy debugging, good for APIs
- **Avro**: Schema evolution, streaming, Hadoop ecosystem
- **Parquet**: Columnar storage, analytical queries, best compression

---

## Results Files

- `results/db_benchmark.txt` ‚Äî Database performance
- `results/format_benchmark.txt` ‚Äî File format comparison
- `results/schema_benchmark.txt` ‚Äî Schema query performance
- `results/pipeline.txt` ‚Äî Pipeline run logs
- `data/exports/` ‚Äî Exported fact tables (Parquet, JSON)

---